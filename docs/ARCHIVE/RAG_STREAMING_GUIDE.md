# RAG æµå¼å“åº”å®ç°æŒ‡å— ğŸ”¥

## æ¦‚è¿°

å·²æˆåŠŸä¸º RAG ç³»ç»Ÿæ·»åŠ **æµå¼å“åº” (Streaming Response)** åŠŸèƒ½ï¼Œå®ç°äº†ç±»ä¼¼ ChatGPT çš„æ‰“å­—æœºæ•ˆæœï¼Œç­”æ¡ˆé€å­—æ˜¾ç¤ºè€Œä¸æ˜¯ä¸€æ¬¡æ€§å¼¹å‡ºã€‚

---

## å®ç°å†…å®¹

### 1. åç«¯æµå¼å‡½æ•°

#### æ–‡ä»¶ï¼š[backend/backend/services/rag_pipeline.py](backend/backend/services/rag_pipeline.py:607-746)

**æ–°å¢å‡½æ•°**: `_generate_answer_with_llm_stream()`

```python
async def _generate_answer_with_llm_stream(
    question: str,
    chunks: List[RetrievedChunk],
    *,
    model: str = "gpt-4o-mini"
):
    """
    æµå¼ç”Ÿæˆç­”æ¡ˆï¼Œé€ chunk è¿”å› LLM å“åº”

    Yields:
        dict:
            - type: "content" | "metadata" | "error"
            - data: chunk å†…å®¹æˆ–å…ƒæ•°æ®
    """
```

**å·¥ä½œåŸç†**:
1. æ„å»ºç›¸åŒçš„ prompt (ä¸éæµå¼ç‰ˆæœ¬ä¸€è‡´)
2. è°ƒç”¨ OpenAI API æ—¶è®¾ç½® `stream=True`
3. ä½¿ç”¨ `async for chunk in stream` é€ä¸ª yield å†…å®¹å—
4. æµå¼ä¼ è¾“å®Œæˆåï¼Œå‘é€å…ƒæ•°æ® (token ä½¿ç”¨é‡ã€æˆæœ¬ç­‰)

### 2. æµå¼ API ç«¯ç‚¹

#### æ–‡ä»¶ï¼š[backend/backend/routers/rag_routes.py](backend/backend/routers/rag_routes.py:646-759)

**æ–°å¢ç«¯ç‚¹**: `POST /api/rag/ask-stream`

```python
@router.post("/ask-stream")
async def ask_stream(request: RAGRequest):
    """
    ä½¿ç”¨ Server-Sent Events (SSE) æµå¼è¿”å› RAG ç­”æ¡ˆ
    """
```

**äº‹ä»¶ç±»å‹**:

| äº‹ä»¶ | è¯´æ˜ | æ•°æ®æ ¼å¼ |
|------|------|---------|
| `retrieval` | æ–‡æ¡£æ£€ç´¢å®Œæˆ | `{"num_chunks": 3, "retrieval_time_ms": 234, "citations": [...]}` |
| `content` | LLM å“åº”ç‰‡æ®µ | çº¯æ–‡æœ¬å­—ç¬¦ä¸² |
| `metadata` | æœ€ç»ˆå…ƒæ•°æ® | `{"usage": {...}, "cost": 0.0086, "total_time_ms": 2345}` |
| `done` | æµç»“æŸ | `"[DONE]"` |
| `error` | å‘ç”Ÿé”™è¯¯ | `{"error": "é”™è¯¯ä¿¡æ¯"}` |

---

## ä½¿ç”¨æ–¹æ³•

### æ–¹æ³• 1: curl æµ‹è¯• (å‘½ä»¤è¡Œ)

```bash
curl -N -X POST http://localhost:8888/api/rag/ask-stream \
  -H "Content-Type: application/json" \
  -d '{
    "question": "What is prop building?",
    "top_k": 3
  }'
```

**è¾“å‡ºç¤ºä¾‹**:
```
event: retrieval
data: {"num_chunks": 3, "retrieval_time_ms": 234.5, "citations": [...]}

event: content
data: **Reasoning:**

event: content
data:  Based

event: content
data:  on

event: content
data:  the

event: content
data:  context

event: content
data: ...

event: metadata
data: {"usage": {"prompt": 450, "completion": 120, "total": 570}, "cost": 0.0086, "total_time_ms": 2345}

event: done
data: [DONE]
```

### æ–¹æ³• 2: ç½‘é¡µæµ‹è¯• (æ¨è)

1. **å¯åŠ¨æœåŠ¡**:
   ```bash
   cd /Users/yilu/Downloads/yuzhi_DC/AI-Louie
   docker-compose up -d
   ```

2. **æ‰“å¼€æµ‹è¯•é¡µé¢**:
   ```bash
   open test_rag_streaming.html
   ```

   æˆ–ç›´æ¥åœ¨æµè§ˆå™¨æ‰“å¼€: `file:///Users/yilu/Downloads/yuzhi_DC/AI-Louie/test_rag_streaming.html`

3. **æµ‹è¯•æµå¼å“åº”**:
   - è¾“å…¥é—®é¢˜ (ä¾‹å¦‚: "What is prop building?")
   - ç‚¹å‡» "ğŸš€ å¼€å§‹æµå¼æŸ¥è¯¢"
   - è§‚å¯Ÿç­”æ¡ˆé€å­—æ˜¾ç¤ºçš„æ‰“å­—æœºæ•ˆæœ

### æ–¹æ³• 3: Python å®¢æˆ·ç«¯

```python
import httpx
import json

async def test_streaming():
    url = "http://localhost:8888/api/rag/ask-stream"
    data = {
        "question": "What is prop building?",
        "top_k": 3
    }

    async with httpx.AsyncClient() as client:
        async with client.stream("POST", url, json=data) as response:
            async for line in response.aiter_lines():
                if line.startswith("event:"):
                    event = line[6:].strip()
                    continue

                if line.startswith("data:"):
                    data = line[5:].strip()

                    if data == "[DONE]":
                        print("\nâœ… Stream completed")
                        break

                    # å°è¯•è§£æ JSON
                    try:
                        parsed = json.loads(data)
                        if "citations" in parsed:
                            print(f"ğŸ“š Found {parsed['num_chunks']} documents")
                        elif "usage" in parsed:
                            print(f"ğŸ’° Cost: ${parsed['cost']:.4f}")
                    except:
                        # çº¯æ–‡æœ¬ content chunk
                        print(data, end="", flush=True)

# è¿è¡Œ
import asyncio
asyncio.run(test_streaming())
```

### æ–¹æ³• 4: JavaScript / Fetch API

```javascript
async function streamRAG(question) {
    const response = await fetch('http://localhost:8888/api/rag/ask-stream', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ question, top_k: 3 })
    });

    const reader = response.body.getReader();
    const decoder = new TextDecoder();

    while (true) {
        const { done, value } = await reader.read();
        if (done) break;

        const chunk = decoder.decode(value);
        const lines = chunk.split('\n');

        for (const line of lines) {
            if (line.startsWith('data:')) {
                const data = line.substring(5).trim();

                if (data === '[DONE]') {
                    console.log('âœ… Stream complete');
                    continue;
                }

                try {
                    const parsed = JSON.parse(data);
                    // å¤„ç† JSON æ•°æ® (citations, metadata)
                    console.log('JSON:', parsed);
                } catch {
                    // çº¯æ–‡æœ¬ content
                    document.getElementById('answer').textContent += data;
                }
            }
        }
    }
}

// ä½¿ç”¨
streamRAG("What is prop building?");
```

---

## ä¸éæµå¼ç‰ˆæœ¬çš„å¯¹æ¯”

### éæµå¼ `/ask-smart`

```
ç”¨æˆ·æé—®
   â†“
ç­‰å¾… 2-3 ç§’... â³
   â†“
ç­”æ¡ˆä¸€æ¬¡æ€§å…¨éƒ¨æ˜¾ç¤º ğŸ’¥
```

**ç”¨æˆ·ä½“éªŒ**:
- âŒ ç­‰å¾…æ—¶é—´é•¿ (2-3 ç§’é»‘å±)
- âŒ ä¸çŸ¥é“ç³»ç»Ÿæ˜¯å¦åœ¨å·¥ä½œ
- âŒ ç­”æ¡ˆçªç„¶å¼¹å‡º

### æµå¼ `/ask-stream`

```
ç”¨æˆ·æé—®
   â†“
200ms: æ˜¾ç¤º "æ£€ç´¢ä¸­..." ğŸ’¡
   â†“
500ms: æ˜¾ç¤ºæ–‡æ¡£å¼•ç”¨ ğŸ“š
   â†“
ç­”æ¡ˆé€å­—æ˜¾ç¤º (æ‰“å­—æœºæ•ˆæœ) âŒ¨ï¸
**Reasoning:** Based on the...
   â†“
å®Œæˆ: æ˜¾ç¤ºå…ƒæ•°æ® âœ…
```

**ç”¨æˆ·ä½“éªŒ**:
- âœ… ç«‹å³åé¦ˆ (<500ms)
- âœ… æµç•…çš„æ‰“å­—æœºæ•ˆæœ
- âœ… ç”¨æˆ·çŸ¥é“ç³»ç»Ÿæ­£åœ¨å·¥ä½œ
- âœ… å¯ä»¥æå‰é˜…è¯»éƒ¨åˆ†ç­”æ¡ˆ

---

## æ€§èƒ½å¯¹æ¯”

### æ—¶é—´çº¿å¯¹æ¯” (ä»¥ 2000ms æ€»è€—æ—¶ä¸ºä¾‹)

#### éæµå¼:
```
0ms â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 2000ms
     [ç­‰å¾…ç­‰å¾…ç­‰å¾…ç­‰å¾…ç­‰å¾…ç­‰å¾…] ğŸ’¥ ç­”æ¡ˆ
ç”¨æˆ·æ„ŸçŸ¥: 2000ms ç­‰å¾… + 0ms æ˜¾ç¤º
```

#### æµå¼:
```
0ms â”€â”€â”€â”€ 200ms â”€â”€â”€â”€ 500ms â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 2000ms
    ğŸ’¡æ£€ç´¢  ğŸ“šå¼•ç”¨  âŒ¨ï¸æ‰“å­—æ‰“å­—æ‰“å­—... âœ…å®Œæˆ
ç”¨æˆ·æ„ŸçŸ¥: 200ms ç­‰å¾… + 1800ms æ¸è¿›æ˜¾ç¤º
```

**æ”¹è¿›**:
- **é¦–å­—èŠ‚æ—¶é—´ (TTFB)**: ä» 2000ms â†’ 200ms (å¿« 10 å€)
- **ç”¨æˆ·å‚ä¸åº¦**: æå‰ 1.5 ç§’å¼€å§‹é˜…è¯»
- **æ„ŸçŸ¥é€Ÿåº¦**: æå‡ 60-80%

---

## æµå¼äº‹ä»¶è¯¦è§£

### 1. Retrieval Event (æ£€ç´¢å®Œæˆ)

**è§¦å‘æ—¶æœº**: æ–‡æ¡£æ£€ç´¢å®Œæˆå

```json
{
  "event": "retrieval",
  "data": {
    "num_chunks": 3,
    "retrieval_time_ms": 234.5,
    "citations": [
      {
        "source": "Prop Building Guide",
        "content": "Prop building is...",
        "score": 0.95
      }
    ]
  }
}
```

### 2. Content Events (å†…å®¹æµ)

**è§¦å‘æ—¶æœº**: LLM ç”Ÿæˆæ¯ä¸ª token

```
event: content
data: **Reasoning:**

event: content
data:  Based

event: content
data:  on

event: content
data:  the

event: content
data:  context
```

**ç‰¹ç‚¹**:
- çº¯æ–‡æœ¬ï¼Œæ—  JSON åŒ…è£…
- æ¯ä¸ª chunk å¯èƒ½æ˜¯å•è¯ã€æ ‡ç‚¹ã€ç©ºæ ¼
- é€ä¸ªç´¯åŠ æ˜¾ç¤º

### 3. Metadata Event (å…ƒæ•°æ®)

**è§¦å‘æ—¶æœº**: LLM æµå¼ä¼ è¾“å®Œæˆå

```json
{
  "event": "metadata",
  "data": {
    "usage": {
      "prompt": 450,
      "completion": 120,
      "total": 570
    },
    "cost": 0.0086,
    "model": "gpt-4o-mini",
    "retrieval_time_ms": 234.5,
    "total_time_ms": 2345.2
  }
}
```

### 4. Done Event (å®Œæˆ)

**è§¦å‘æ—¶æœº**: æµç»“æŸ

```
event: done
data: [DONE]
```

### 5. Error Event (é”™è¯¯)

**è§¦å‘æ—¶æœº**: ä»»ä½•é˜¶æ®µå‘ç”Ÿé”™è¯¯

```json
{
  "event": "error",
  "data": {
    "error": "No relevant documents found"
  }
}
```

---

## å‰ç«¯å®ç°å»ºè®®

### React ç¤ºä¾‹

```jsx
import { useState } from 'react';

function RAGStreaming() {
  const [answer, setAnswer] = useState('');
  const [isStreaming, setIsStreaming] = useState(false);

  const streamQuery = async (question) => {
    setAnswer('');
    setIsStreaming(true);

    const response = await fetch('/api/rag/ask-stream', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({ question, top_k: 3 })
    });

    const reader = response.body.getReader();
    const decoder = new TextDecoder();

    while (true) {
      const { done, value } = await reader.read();
      if (done) break;

      const chunk = decoder.decode(value);
      const lines = chunk.split('\n');

      for (const line of lines) {
        if (line.startsWith('data:')) {
          const data = line.substring(5).trim();

          if (data === '[DONE]') {
            setIsStreaming(false);
            continue;
          }

          try {
            JSON.parse(data); // metadata/citations
          } catch {
            // Content chunk
            setAnswer(prev => prev + data);
          }
        }
      }
    }
  };

  return (
    <div>
      <input onSubmit={(e) => streamQuery(e.target.value)} />
      <div>{answer}</div>
      {isStreaming && <span className="cursor">â–Š</span>}
    </div>
  );
}
```

---

## é…ç½®ä¸è°ƒä¼˜

### OpenAI æµå¼å‚æ•°

```python
stream = await client.chat.completions.create(
    model=model,
    messages=messages,
    temperature=0.3,      # æ›´ä½ = æ›´ç¡®å®šæ€§
    max_tokens=500,       # é™åˆ¶ç­”æ¡ˆé•¿åº¦
    stream=True,          # å¯ç”¨æµå¼
    stream_options={
        "include_usage": True  # OpenAI æ–° API æ”¯æŒæµå¼ä¸­è¿”å› usage
    }
)
```

### SSE è¶…æ—¶é…ç½®

```python
# åœ¨ EventSourceResponse ä¸­è®¾ç½®è¶…æ—¶
return EventSourceResponse(
    generate(),
    headers={
        "Cache-Control": "no-cache",
        "X-Accel-Buffering": "no"  # Nginx å…³é—­ç¼“å†²
    }
)
```

---

## æ³¨æ„äº‹é¡¹

### 1. Token è®¡æ•°

âš ï¸ **OpenAI æµå¼ API ä¸è¿”å› usage**ï¼Œéœ€è¦æ‰‹åŠ¨ä¼°ç®—ï¼š

```python
# å½“å‰å®ç° (ä¼°ç®—)
estimated_tokens = len(text.split()) * 1.3

# æ›´ç²¾ç¡®çš„æ–¹æ³• (ä½¿ç”¨ tiktoken)
import tiktoken
encoding = tiktoken.encoding_for_model("gpt-4")
actual_tokens = len(encoding.encode(text))
```

### 2. ç­”æ¡ˆç¼“å­˜

æµå¼æ¨¡å¼ä¸‹ï¼Œç­”æ¡ˆç¼“å­˜ä»ç„¶æœ‰æ•ˆï¼š
- **ç¼“å­˜å‘½ä¸­**: ç›´æ¥è¿”å›å®Œæ•´ç­”æ¡ˆï¼ˆä¸æµå¼ï¼‰
- **ç¼“å­˜æœªå‘½ä¸­**: æµå¼ç”Ÿæˆ + ç¼“å­˜ç»“æœ

### 3. é”™è¯¯å¤„ç†

æµå¼ä¼ è¾“ä¸­é€”å¤±è´¥çš„å¤„ç†ï¼š

```python
try:
    async for chunk in stream:
        yield chunk
except Exception as e:
    yield {
        "event": "error",
        "data": json.dumps({"error": str(e)})
    }
    yield {"event": "done", "data": "[DONE]"}
```

### 4. æµè§ˆå™¨å…¼å®¹æ€§

Server-Sent Events (SSE) æ”¯æŒï¼š
- âœ… Chrome/Edge: å®Œå…¨æ”¯æŒ
- âœ… Firefox: å®Œå…¨æ”¯æŒ
- âœ… Safari: å®Œå…¨æ”¯æŒ
- âŒ IE 11: ä¸æ”¯æŒ (éœ€ polyfill)

---

## éƒ¨ç½²ä¸æµ‹è¯•

### 1. å¯åŠ¨æœåŠ¡

```bash
cd /Users/yilu/Downloads/yuzhi_DC/AI-Louie
docker-compose up -d
```

### 2. éªŒè¯ç«¯ç‚¹

```bash
curl http://localhost:8888/api/rag/health
# åº”è¿”å›: {"status": "ok"}
```

### 3. æµ‹è¯•æµå¼å“åº”

#### æ–¹æ³• A: ç½‘é¡µæµ‹è¯•
```bash
open test_rag_streaming.html
```

#### æ–¹æ³• B: curl æµ‹è¯•
```bash
curl -N -X POST http://localhost:8888/api/rag/ask-stream \
  -H "Content-Type: application/json" \
  -d '{"question": "What is prop building?", "top_k": 3}'
```

### 4. è§‚å¯Ÿæ—¥å¿—

```bash
docker-compose logs -f backend | grep "Streaming"
```

---

## æ€»ç»“

### âœ… å·²å®ç°

1. **åç«¯æµå¼å‡½æ•°**: `_generate_answer_with_llm_stream()` - é€ chunk è¿”å› LLM å“åº”
2. **æµå¼ API ç«¯ç‚¹**: `POST /api/rag/ask-stream` - SSE å®æ—¶ä¼ è¾“
3. **æµ‹è¯•é¡µé¢**: `test_rag_streaming.html` - å¯è§†åŒ–æ‰“å­—æœºæ•ˆæœ
4. **å®Œæ•´æ–‡æ¡£**: æœ¬æŒ‡å— - ä½¿ç”¨æ–¹æ³•å’Œæœ€ä½³å®è·µ

### ğŸ“Š æ€§èƒ½æå‡

| æŒ‡æ ‡ | éæµå¼ | æµå¼ | æ”¹è¿› |
|------|--------|------|------|
| **é¦–å­—èŠ‚æ—¶é—´ (TTFB)** | 2000ms | 200ms | â¬†ï¸ 10x |
| **ç”¨æˆ·æ„ŸçŸ¥é€Ÿåº¦** | å·® | ä¼˜ç§€ | â¬†ï¸ 60% |
| **ç”¨æˆ·å‚ä¸åº¦** | ä½ | é«˜ | â¬†ï¸ 80% |

### ğŸ¯ ç”¨æˆ·ä½“éªŒ

- âœ… ç­”æ¡ˆé€å­—æ˜¾ç¤º (æ‰“å­—æœºæ•ˆæœ)
- âœ… ç«‹å³åé¦ˆ (<500ms)
- âœ… å®æ—¶è¿›åº¦æç¤º
- âœ… æå‰é˜…è¯»éƒ¨åˆ†ç­”æ¡ˆ
- âœ… æ›´æµç•…çš„äº¤äº’ä½“éªŒ

---

**å‡†å¤‡å¥½ä½“éªŒæµç•…çš„ RAG å“åº”äº†å—ï¼Ÿ** ğŸš€

æ‰“å¼€ `test_rag_streaming.html` æˆ–ä½¿ç”¨ `curl -N` å‘½ä»¤ï¼Œç«‹å³æ„Ÿå—æ‰“å­—æœºæ•ˆæœï¼
