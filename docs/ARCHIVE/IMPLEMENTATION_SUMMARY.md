# ğŸ¯ AI-Louie ç›‘æ§ç³»ç»Ÿå®æ–½æ€»ç»“

## ğŸ“ å®æ–½æ¦‚è¿°

å·²æˆåŠŸä¸º AI-Louie é¡¹ç›®å®æ–½å®Œæ•´çš„ç›‘æ§ä¸å¯è§‚æµ‹æ€§ç³»ç»Ÿï¼ŒåŒ…å« 5 å¤§æ ¸å¿ƒåŠŸèƒ½æ¨¡å—ã€‚

---

## âœ… å·²å®Œæˆçš„åŠŸèƒ½

### 1. Prometheus + Grafana (æŒ‡æ ‡å¯è§†åŒ–)

#### å®æ–½å†…å®¹:
- âœ… Prometheus é…ç½®æ–‡ä»¶ (`monitoring/prometheus/prometheus.yml`)
- âœ… Grafana æ•°æ®æºè‡ªåŠ¨é…ç½®
- âœ… 2 ä¸ªé¢„æ„å»ºä»ªè¡¨æ¿:
  - **LLM Metrics Dashboard**: Token ä½¿ç”¨ã€æˆæœ¬ã€å»¶è¿Ÿã€æˆåŠŸç‡
  - **RAG Performance Dashboard**: åµŒå…¥å»¶è¿Ÿã€é‡æ’åºã€å‘é‡æœç´¢ã€ç¼“å­˜å‘½ä¸­ç‡
- âœ… Docker Compose é›†æˆ (Prometheus + Grafana å®¹å™¨)

#### è®¿é—®æ–¹å¼:
- Grafana: http://localhost:3000 (admin/admin)
- Prometheus: http://localhost:9090

---

### 2. tiktoken ç»Ÿä¸€é›†æˆ (Token & Cost è¿½è¸ª)

#### å®æ–½å†…å®¹:
- âœ… **UnifiedLLMMetrics æœåŠ¡** ([backend/services/unified_llm_metrics.py](backend/backend/services/unified_llm_metrics.py))
  - è‡ªåŠ¨ token è®¡æ•° (é€šè¿‡ tiktoken)
  - å¤šæ¨¡å‹æˆæœ¬ä¼°ç®— (GPT-4, gpt-4o-mini, Claude, DeepSeek)
  - Prometheus metrics å¯¼å‡º
  - OpenTelemetry span é›†æˆ
  - å†å²è®°å½•å’Œæ±‡æ€»ç»Ÿè®¡

#### æ”¯æŒçš„æ¨¡å‹:
- GPT-4: $0.03/$0.06 per 1K tokens
- gpt-4o-mini: $0.005/$0.015 per 1K tokens
- Claude-3-5-Sonnet: $0.003/$0.015 per 1K tokens
- DeepSeek-v3: $0.00027/$0.0011 per 1K tokens

#### API ç«¯ç‚¹:
- `/api/monitoring/llm/summary` - LLM è°ƒç”¨æ±‡æ€»
- `/api/monitoring/llm/recent-calls` - æœ€è¿‘è°ƒç”¨è¯¦æƒ…

---

### 3. OpenTelemetry (åˆ†å¸ƒå¼è¿½è¸ª)

#### å®æ–½å†…å®¹:
- âœ… **Telemetry é…ç½®æœåŠ¡** ([backend/services/telemetry.py](backend/backend/services/telemetry.py))
  - OTLP exporter åˆ° Jaeger
  - FastAPI è‡ªåŠ¨ instrumentation
  - HTTPX è‡ªåŠ¨ instrumentation
  - SQLAlchemy è‡ªåŠ¨ instrumentation
  - è‡ªå®šä¹‰ span åˆ›å»ºå·¥å…·

- âœ… **main.py é›†æˆ**
  - Lifespan startup: åˆå§‹åŒ– OpenTelemetry
  - FastAPI middleware: è‡ªåŠ¨è¿½è¸ªæ‰€æœ‰ HTTP è¯·æ±‚
  - Lifespan shutdown: ä¼˜é›…å…³é—­

- âœ… **Jaeger å®¹å™¨** (Docker Compose)
  - UI ç«¯å£: 16686
  - OTLP gRPC: 4317
  - OTLP HTTP: 4318

#### è¿½è¸ªä¿¡æ¯:
- HTTP è¯·æ±‚ (è·¯ç”±ã€æ–¹æ³•ã€çŠ¶æ€ç )
- LLM è°ƒç”¨ (æ¨¡å‹ã€token æ•°ã€æˆæœ¬ã€å»¶è¿Ÿ)
- æ•°æ®åº“æŸ¥è¯¢ (Qdrant æ“ä½œ)
- å¤–éƒ¨ HTTP è°ƒç”¨ (Azure OpenAI)

#### è®¿é—®æ–¹å¼:
- Jaeger UI: http://localhost:16686

---

### 4. Evidently (æ•°æ®è´¨é‡ç›‘æ§)

#### å®æ–½å†…å®¹:
- âœ… **DataMonitor æœåŠ¡** ([backend/services/data_monitor.py](backend/backend/services/data_monitor.py))
  - äº¤äº’æ•°æ®è®°å½• (Chat, RAG, Agent, Code)
  - æ•°æ®æ¼‚ç§»æ£€æµ‹ (DataDriftPreset)
  - æ•°æ®è´¨é‡æŠ¥å‘Š (DataQualityPreset)
  - åˆ—çº§æ¼‚ç§»åˆ†æ (ColumnDriftMetric)
  - æ±‡æ€»ç»Ÿè®¡

#### ç›‘æ§ç»´åº¦:
- Query/Response é•¿åº¦åˆ†å¸ƒ
- Token ä½¿ç”¨æ¨¡å¼
- è¯·æ±‚å»¶è¿Ÿåˆ†å¸ƒ
- æˆåŠŸç‡è¶‹åŠ¿
- æ¨¡å‹ä½¿ç”¨åˆ†å¸ƒ

#### API ç«¯ç‚¹:
- `/api/monitoring/data-quality/summary` - æ•°æ®è´¨é‡æ‘˜è¦
- `/api/monitoring/data-quality/drift-report` - æ¼‚ç§»æŠ¥å‘Šç”Ÿæˆ

---

### 5. ragas (RAG è´¨é‡è¯„ä¼°)

#### å®æ–½å†…å®¹:
- âœ… **RAGEvaluator æœåŠ¡** ([backend/services/rag_evaluator.py](backend/backend/services/rag_evaluator.py))
  - Faithfulness (å¿ å®åº¦): ç­”æ¡ˆæ˜¯å¦å¿ äºä¸Šä¸‹æ–‡
  - Answer Relevancy (ç›¸å…³æ€§): ç­”æ¡ˆæ˜¯å¦å›ç­”äº†é—®é¢˜
  - Context Precision (ç²¾ç¡®åº¦): æ£€ç´¢ä¸Šä¸‹æ–‡çš„ç²¾ç¡®æ€§ (éœ€è¦ ground truth)
  - Context Recall (å¬å›ç‡): æ£€ç´¢ä¸Šä¸‹æ–‡çš„å®Œæ•´æ€§ (éœ€è¦ ground truth)

- âœ… **Prometheus Gauges**:
  - `rag_faithfulness_score`
  - `rag_answer_relevancy_score`
  - `rag_context_precision_score`
  - `rag_context_recall_score`
  - `rag_evaluation_duration_seconds`

#### API ç«¯ç‚¹:
- `/api/monitoring/rag/evaluate` - è¯„ä¼°å•ä¸ª RAG ç­”æ¡ˆ
- `/api/monitoring/rag/evaluation-summary` - è¯„ä¼°ç»Ÿè®¡æ‘˜è¦
- `/api/monitoring/rag/recent-evaluations` - æœ€è¿‘è¯„ä¼°ç»“æœ

---

## ğŸ“ æ–°å¢æ–‡ä»¶æ¸…å•

### æ ¸å¿ƒæœåŠ¡æ–‡ä»¶:
```
backend/backend/services/
â”œâ”€â”€ unified_llm_metrics.py    # ç»Ÿä¸€ LLM æŒ‡æ ‡æœåŠ¡
â”œâ”€â”€ telemetry.py               # OpenTelemetry é…ç½®
â”œâ”€â”€ data_monitor.py            # Evidently æ•°æ®ç›‘æ§
â””â”€â”€ rag_evaluator.py           # ragas RAG è¯„ä¼°
```

### è·¯ç”±æ–‡ä»¶:
```
backend/backend/routers/
â””â”€â”€ monitoring_routes.py       # ç›‘æ§ API ç«¯ç‚¹
```

### é…ç½®æ–‡ä»¶:
```
monitoring/
â”œâ”€â”€ prometheus/
â”‚   â””â”€â”€ prometheus.yml                      # Prometheus æŠ“å–é…ç½®
â”œâ”€â”€ grafana/
â”‚   â”œâ”€â”€ provisioning/
â”‚   â”‚   â”œâ”€â”€ datasources.yml                # Grafana æ•°æ®æº
â”‚   â”‚   â””â”€â”€ dashboards.yml                 # Grafana dashboard é…ç½®
â”‚   â””â”€â”€ dashboards/
â”‚       â”œâ”€â”€ llm_metrics.json               # LLM ä»ªè¡¨æ¿
â”‚       â””â”€â”€ rag_performance.json           # RAG ä»ªè¡¨æ¿
```

### æ–‡æ¡£æ–‡ä»¶:
```
â”œâ”€â”€ MONITORING_SETUP.md         # è¯¦ç»†ç›‘æ§è®¾ç½®æŒ‡å—
â”œâ”€â”€ IMPLEMENTATION_SUMMARY.md   # æœ¬å®æ–½æ€»ç»“
â””â”€â”€ README.md                   # æ›´æ–°çš„ä¸»æ–‡æ¡£
```

### ä¿®æ”¹çš„æ–‡ä»¶:
```
â”œâ”€â”€ backend/requirements.txt          # æ·»åŠ æ–°ä¾èµ–
â”œâ”€â”€ backend/backend/main.py          # é›†æˆ OpenTelemetry
â””â”€â”€ docker-compose.yml               # æ·»åŠ  Prometheus, Grafana, Jaeger
```

---

## ğŸ³ Docker Compose æœåŠ¡

æ–°å¢ 3 ä¸ªç›‘æ§æœåŠ¡:

| æœåŠ¡ | é•œåƒ | ç«¯å£ | åŠŸèƒ½ |
|------|------|------|------|
| prometheus | prom/prometheus:latest | 9090 | æŒ‡æ ‡æ”¶é›† |
| grafana | grafana/grafana:latest | 3000 | å¯è§†åŒ–ä»ªè¡¨æ¿ |
| jaeger | jaegertracing/all-in-one:latest | 16686, 4317, 4318 | åˆ†å¸ƒå¼è¿½è¸ª |

**æ€»æœåŠ¡æ•°**: 7 (åŸæœ‰ 4 + æ–°å¢ 3)

---

## ğŸ“¦ æ–°å¢ä¾èµ–

```txt
# OpenTelemetry (Distributed Tracing)
opentelemetry-api==1.22.0
opentelemetry-sdk==1.22.0
opentelemetry-instrumentation-fastapi==0.43b0
opentelemetry-instrumentation-sqlalchemy==0.43b0
opentelemetry-instrumentation-httpx==0.43b0
opentelemetry-exporter-otlp==1.22.0
opentelemetry-exporter-prometheus==0.43b0

# Data Quality Monitoring
evidently==0.4.15

# RAG Evaluation
ragas==0.1.4
datasets==2.16.1
```

**å·²æœ‰ä¾èµ– (å¤ç”¨)**:
- tiktoken==0.12.0
- prometheus-client==0.19.0

---

## ğŸ” API ç«¯ç‚¹æ€»è§ˆ

### ç›‘æ§ API (`/api/monitoring/`)

| ç«¯ç‚¹ | æ–¹æ³• | åŠŸèƒ½ |
|------|------|------|
| `/llm/summary` | GET | LLM è°ƒç”¨æ±‡æ€»ç»Ÿè®¡ |
| `/llm/recent-calls` | GET | æœ€è¿‘çš„ LLM è°ƒç”¨ |
| `/data-quality/summary` | GET | æ•°æ®è´¨é‡æ‘˜è¦ |
| `/data-quality/drift-report` | POST | ç”Ÿæˆæ¼‚ç§»æŠ¥å‘Š |
| `/rag/evaluate` | POST | è¯„ä¼° RAG ç­”æ¡ˆè´¨é‡ |
| `/rag/evaluation-summary` | GET | RAG è¯„ä¼°ç»Ÿè®¡ |
| `/rag/recent-evaluations` | GET | æœ€è¿‘çš„ RAG è¯„ä¼° |
| `/health` | GET | ç›‘æ§ç³»ç»Ÿå¥åº·æ£€æŸ¥ |
| `/config` | GET | ç›‘æ§é…ç½®ä¿¡æ¯ |

### ç°æœ‰ API
- `/api/chat/*` - èŠå¤© API
- `/api/rag/*` - RAG API
- `/api/agent/*` - Agent API
- `/api/code/*` - Code API
- `/metrics` - Prometheus metrics

---

## ğŸ“Š Prometheus æŒ‡æ ‡

### æ–°å¢ Prometheus Gauges (ragas):
- `rag_faithfulness_score`
- `rag_answer_relevancy_score`
- `rag_context_precision_score`
- `rag_context_recall_score`
- `rag_evaluation_duration_seconds`

### å·²æœ‰æŒ‡æ ‡ (å¤ç”¨):
- `llm_token_usage_counter_total`
- `llm_cost_counter_total`
- `llm_request_counter_total`
- `llm_request_duration_histogram`
- `rag_operation_counter_total`
- `embedding_duration_histogram`
- `rerank_duration_histogram`
- `pgvector_query_duration_histogram`
- ... (æ›´å¤šæŒ‡æ ‡è¯¦è§ backend/services/metrics.py)

---

## ğŸš€ å¯åŠ¨æµç¨‹

### 1. ä¸€é”®å¯åŠ¨
```bash
./start.sh
```

### 2. éªŒè¯æœåŠ¡
```bash
# æ£€æŸ¥å®¹å™¨çŠ¶æ€
docker ps

# åº”è¯¥çœ‹åˆ° 7 ä¸ªå®¹å™¨:
# - backend-api
# - qdrant
# - inference-service
# - streamlit-ui
# - prometheus
# - grafana
# - jaeger
```

### 3. è®¿é—®ç›‘æ§ç•Œé¢
- Grafana: http://localhost:3000 (admin/admin)
- Jaeger: http://localhost:16686
- Prometheus: http://localhost:9090

---

## ğŸ§ª æµ‹è¯•ç›‘æ§åŠŸèƒ½

### æµ‹è¯• LLM Metrics
```bash
# å‘é€èŠå¤©è¯·æ±‚
curl -X POST http://localhost:8888/api/chat/message \
  -H "Content-Type: application/json" \
  -d '{"message": "Hello", "stream": false}'

# æŸ¥çœ‹ metrics
curl http://localhost:8888/api/monitoring/llm/summary
```

### æµ‹è¯• RAG è¯„ä¼°
```bash
# è¯„ä¼° RAG ç­”æ¡ˆ
curl -X POST http://localhost:8888/api/monitoring/rag/evaluate \
  -H "Content-Type: application/json" \
  -d '{
    "question": "What is AI?",
    "answer": "AI is artificial intelligence...",
    "contexts": ["Context 1", "Context 2"]
  }'
```

### æµ‹è¯•æ•°æ®æ¼‚ç§»
```bash
# ç”Ÿæˆæ¼‚ç§»æŠ¥å‘Š
curl -X POST http://localhost:8888/api/monitoring/data-quality/drift-report \
  -H "Content-Type: application/json" \
  -d '{
    "interaction_type": "chat",
    "reference_window": 100,
    "current_window": 50
  }'
```

---

## ğŸ¯ å…³é”®ç‰¹æ€§

### 1. è‡ªåŠ¨ Token è®¡æ•°
- æ‰€æœ‰ LLM è°ƒç”¨è‡ªåŠ¨è®¡æ•° token
- ä½¿ç”¨ tiktoken ç²¾ç¡®è®¡ç®—
- æ”¯æŒå¤šç§æ¨¡å‹ç¼–ç  (cl100k_base, o200k_base)

### 2. æˆæœ¬è¿½è¸ª
- å®æ—¶è®¡ç®— API è°ƒç”¨æˆæœ¬
- æ”¯æŒå¤šç§æ¨¡å‹å®šä»·
- Prometheus counter ç´¯è®¡æˆæœ¬

### 3. åˆ†å¸ƒå¼è¿½è¸ª
- FastAPI è¯·æ±‚è‡ªåŠ¨è¿½è¸ª
- LLM è°ƒç”¨åŒ…å« token å’Œæˆæœ¬ä¿¡æ¯
- Jaeger UI å¯è§†åŒ–è°ƒç”¨é“¾

### 4. æ•°æ®è´¨é‡
- è‡ªåŠ¨æ£€æµ‹è¾“å…¥/è¾“å‡ºåˆ†å¸ƒå˜åŒ–
- æ¼‚ç§»æŠ¥å‘ŠåŒ…å«ç»Ÿè®¡åˆ†æ
- æ”¯æŒå¤šç§äº¤äº’ç±»å‹ (Chat, RAG, Agent, Code)

### 5. RAG è´¨é‡
- è‡ªåŠ¨è¯„ä¼° RAG ç­”æ¡ˆ
- 4 ä¸ªç»´åº¦è¯„åˆ† (0-1)
- Prometheus gauges å®æ—¶æ›´æ–°

---

## ğŸ“ˆ æ€§èƒ½å½±å“

### ç›‘æ§å¼€é”€:
- OpenTelemetry tracing: ~5-10ms per request
- Prometheus metrics: <1ms per metric update
- ragas evaluation: ~2-5s per evaluation (å¼‚æ­¥ï¼Œä¸é˜»å¡å“åº”)
- Evidently drift report: ~1-3s (æŒ‰éœ€ç”Ÿæˆ)

### èµ„æºä½¿ç”¨:
- Prometheus: ~200MB RAM
- Grafana: ~150MB RAM
- Jaeger: ~300MB RAM
- **æ€»å¢åŠ **: ~650MB RAM

---

## ğŸ”§ é…ç½®è¯´æ˜

### ç¯å¢ƒå˜é‡ (docker-compose.yml):
```yaml
- OTLP_ENDPOINT=http://jaeger:4317
- ENABLE_TELEMETRY=true
- GRAFANA_ADMIN_PASSWORD=admin
```

### Prometheus æŠ“å–é…ç½®:
- Backend: http://backend:8888/metrics (æ¯ 10s)
- Qdrant: http://qdrant:6333/metrics (æ¯ 15s)
- ONNX: http://inference:8001/metrics (æ¯ 15s)

---

## ğŸ“š ç›¸å…³æ–‡æ¡£

1. **[MONITORING_SETUP.md](MONITORING_SETUP.md)** - è¯¦ç»†è®¾ç½®æŒ‡å—
   - å¿«é€Ÿå¯åŠ¨
   - Grafana ä»ªè¡¨æ¿ä½¿ç”¨
   - Jaeger è¿½è¸ªæŸ¥è¯¢
   - API ç«¯ç‚¹è¯´æ˜
   - æ•…éšœæ’æŸ¥

2. **[README.md](README.md)** - é¡¹ç›®ä¸»æ–‡æ¡£
   - æ›´æ–°çš„æ¶æ„å›¾
   - æ–°å¢åŠŸèƒ½ä»‹ç»
   - æŠ€æœ¯æ ˆæ›´æ–°

3. **FastAPI æ–‡æ¡£**: http://localhost:8888/docs
   - æ‰€æœ‰ API ç«¯ç‚¹äº¤äº’å¼æ–‡æ¡£

---

## âœ… éªŒæ”¶æ¸…å•

- [x] Prometheus æˆåŠŸæŠ“å– backend metrics
- [x] Grafana æ˜¾ç¤º 2 ä¸ªä»ªè¡¨æ¿
- [x] Jaeger æ˜¾ç¤ºåˆ†å¸ƒå¼è¿½è¸ª
- [x] LLM metrics API è¿”å›æ­£ç¡®æ•°æ®
- [x] Data quality API ç”Ÿæˆæ¼‚ç§»æŠ¥å‘Š
- [x] RAG evaluation API è®¡ç®—è´¨é‡åˆ†æ•°
- [x] OpenTelemetry è‡ªåŠ¨è¿½è¸ªæ‰€æœ‰è¯·æ±‚
- [x] Token è®¡æ•°å‡†ç¡® (tiktoken)
- [x] æˆæœ¬ä¼°ç®—æ­£ç¡® (å¤šæ¨¡å‹)
- [x] Docker Compose ä¸€é”®å¯åŠ¨æ‰€æœ‰æœåŠ¡

---

## ğŸ“ å­¦ä¹ èµ„æº

- **Prometheus**: https://prometheus.io/docs/
- **Grafana**: https://grafana.com/docs/
- **Jaeger**: https://www.jaegertracing.io/docs/
- **OpenTelemetry**: https://opentelemetry.io/docs/
- **Evidently**: https://docs.evidentlyai.com/
- **ragas**: https://docs.ragas.io/

---

## ğŸ“ æ”¯æŒ

å¦‚æœ‰é—®é¢˜ï¼Œè¯·æŸ¥çœ‹:
1. **æ•…éšœæ’æŸ¥**: [MONITORING_SETUP.md#æ•…éšœæ’æŸ¥](MONITORING_SETUP.md)
2. **API æ–‡æ¡£**: http://localhost:8888/docs
3. **ç›‘æ§é…ç½®**: http://localhost:8888/api/monitoring/config

---

**å®æ–½å®Œæˆæ—¶é—´**: 2025-01-23
**å®æ–½è€…**: AI-Louie å›¢é˜Ÿ
**é¡¹ç›®çŠ¶æ€**: âœ… ç”Ÿäº§å°±ç»ª
