# ğŸ” AI-Louie ç›‘æ§ç³»ç»Ÿè®¾ç½®æŒ‡å—

æœ¬æ–‡æ¡£ä»‹ç»å¦‚ä½•ä½¿ç”¨æ–°å¢çš„ç›‘æ§å’Œå¯è§‚æµ‹æ€§åŠŸèƒ½ã€‚

## ğŸ“Š æ–°å¢åŠŸèƒ½æ¦‚è§ˆ

### 1. Prometheus + Grafana (æŒ‡æ ‡å¯è§†åŒ–)
- **Prometheus**: æ—¶åºæŒ‡æ ‡æ”¶é›†å’Œå­˜å‚¨
- **Grafana**: å®æ—¶å¯è§†åŒ–ä»ªè¡¨æ¿
- **è®¿é—®åœ°å€**: http://localhost:3000 (é»˜è®¤å¯†ç : admin/admin)

### 2. OpenTelemetry (åˆ†å¸ƒå¼è¿½è¸ª)
- **Jaeger UI**: åˆ†å¸ƒå¼è¿½è¸ªå¯è§†åŒ–
- **è®¿é—®åœ°å€**: http://localhost:16686
- **åŠŸèƒ½**: è¿½è¸ªå®Œæ•´è¯·æ±‚é“¾è·¯ (FastAPI â†’ LLM â†’ Qdrant)

### 3. Evidently (æ•°æ®è´¨é‡ç›‘æ§)
- **æ•°æ®æ¼‚ç§»æ£€æµ‹**: è‡ªåŠ¨æ£€æµ‹è¾“å…¥/è¾“å‡ºåˆ†å¸ƒå˜åŒ–
- **API ç«¯ç‚¹**: `/api/monitoring/data-quality/*`

### 4. ragas (RAG è´¨é‡è¯„ä¼°)
- **è‡ªåŠ¨è¯„ä¼°**: Faithfulness, Relevancy, Precision, Recall
- **API ç«¯ç‚¹**: `/api/monitoring/rag/*`

### 5. ç»Ÿä¸€ LLM Metrics
- **Token è®¡æ•°**: è‡ªåŠ¨è·Ÿè¸ªæ‰€æœ‰ LLM è°ƒç”¨çš„ token ä½¿ç”¨
- **æˆæœ¬è¿½è¸ª**: å®æ—¶è®¡ç®— API è°ƒç”¨æˆæœ¬
- **API ç«¯ç‚¹**: `/api/monitoring/llm/*`

---

## ğŸš€ å¿«é€Ÿå¯åŠ¨

### 1. å¯åŠ¨æ‰€æœ‰æœåŠ¡

```bash
# ä¸€é”®å¯åŠ¨ï¼ˆåŒ…å«æ‰€æœ‰ç›‘æ§æœåŠ¡ï¼‰
./start.sh

# æˆ–ä½¿ç”¨ docker-compose
docker-compose up -d
```

### 2. éªŒè¯æœåŠ¡çŠ¶æ€

```bash
# æ£€æŸ¥æ‰€æœ‰å®¹å™¨
docker ps

# åº”è¯¥çœ‹åˆ°ä»¥ä¸‹å®¹å™¨:
# - backend-api (FastAPI)
# - qdrant (å‘é‡æ•°æ®åº“)
# - prometheus (æŒ‡æ ‡æ”¶é›†)
# - grafana (å¯è§†åŒ–)
# - jaeger (åˆ†å¸ƒå¼è¿½è¸ª)
# - streamlit-ui (å‰ç«¯)
# - inference-service (ONNX æ¨ç†)
```

### 3. è®¿é—®ç›‘æ§ç•Œé¢

| æœåŠ¡ | URL | é»˜è®¤å‡­æ® | åŠŸèƒ½ |
|------|-----|----------|------|
| **Grafana** | http://localhost:3000 | admin/admin | LLM & RAG ä»ªè¡¨æ¿ |
| **Prometheus** | http://localhost:9090 | æ— éœ€è®¤è¯ | åŸå§‹æŒ‡æ ‡æŸ¥è¯¢ |
| **Jaeger** | http://localhost:16686 | æ— éœ€è®¤è¯ | åˆ†å¸ƒå¼è¿½è¸ª |
| **FastAPI Docs** | http://localhost:8888/docs | æ— éœ€è®¤è¯ | API æ–‡æ¡£ |
| **Prometheus /metrics** | http://localhost:8888/metrics | æ— éœ€è®¤è¯ | åŸå§‹æŒ‡æ ‡å¯¼å‡º |

---

## ğŸ“ˆ Grafana ä»ªè¡¨æ¿

### é¢„é…ç½®ä»ªè¡¨æ¿

å·²åŒ…å«ä¸¤ä¸ªé¢„é…ç½®ä»ªè¡¨æ¿ï¼š

#### 1. LLM Metrics Dashboard
- **LLM è¯·æ±‚é€Ÿç‡**: æ¯ç§’è¯·æ±‚æ•° (æŒ‰æ¨¡å‹/çŠ¶æ€)
- **Token ä½¿ç”¨é‡**: Prompt & Completion tokens
- **API æˆæœ¬**: å®æ—¶æˆæœ¬è¿½è¸ª (USD)
- **è¯·æ±‚å»¶è¿Ÿ**: P95 å»¶è¿Ÿåˆ†å¸ƒ
- **æˆåŠŸç‡**: è¯·æ±‚æˆåŠŸç‡ä»ªè¡¨ç›˜

#### 2. RAG Performance Dashboard
- **RAG è¯·æ±‚é€Ÿç‡**: æ£€ç´¢æ“ä½œé¢‘ç‡
- **åµŒå…¥å»¶è¿Ÿ**: å‘é‡ç”Ÿæˆæ€§èƒ½
- **é‡æ’åºå»¶è¿Ÿ**: é‡æ’åºæ€§èƒ½
- **å‘é‡æœç´¢å»¶è¿Ÿ**: P50/P95/P99 åˆ†å¸ƒ
- **ç¼“å­˜å‘½ä¸­ç‡**: åµŒå…¥ç¼“å­˜æ•ˆç‡
- **ç«¯åˆ°ç«¯å»¶è¿Ÿ**: å®Œæ•´ RAG æµç¨‹å»¶è¿Ÿ
- **é‡æ’åºåˆ†æ•°åˆ†å¸ƒ**: çƒ­åŠ›å›¾
- **é”™è¯¯ç‡**: æ¨ç†æœåŠ¡é”™è¯¯ç›‘æ§
- **ç†”æ–­å™¨çŠ¶æ€**: æœåŠ¡å¥åº·ç›‘æ§

### è‡ªå®šä¹‰ä»ªè¡¨æ¿

åœ¨ Grafana UI ä¸­:
1. ç‚¹å‡» "+" â†’ "Dashboard"
2. æ·»åŠ  Panel
3. é€‰æ‹© Prometheus æ•°æ®æº
4. ä½¿ç”¨ä»¥ä¸‹æŒ‡æ ‡:
   - `llm_token_usage_counter_total`
   - `llm_cost_counter_total`
   - `llm_request_duration_histogram_bucket`
   - `rag_operation_counter_total`
   - `embedding_duration_histogram_bucket`
   - `rerank_duration_histogram_bucket`

---

## ğŸ” Jaeger åˆ†å¸ƒå¼è¿½è¸ª

### æŸ¥çœ‹è¿½è¸ª

1. è®¿é—® http://localhost:16686
2. ä» "Service" ä¸‹æ‹‰èœå•é€‰æ‹© `ai-louie-backend`
3. ç‚¹å‡» "Find Traces" æŸ¥çœ‹æœ€è¿‘çš„è¿½è¸ª

### è¿½è¸ªä¿¡æ¯åŒ…å«:

- **HTTP è¯·æ±‚**: FastAPI è·¯ç”±
- **LLM è°ƒç”¨**: Token æ•°é‡ã€æˆæœ¬ã€å»¶è¿Ÿ
- **æ•°æ®åº“æŸ¥è¯¢**: Qdrant å‘é‡æœç´¢
- **å¤–éƒ¨ HTTP è°ƒç”¨**: Azure OpenAI API

### ç¤ºä¾‹æŸ¥è¯¢:

- æŸ¥æ‰¾æ…¢è¯·æ±‚: `duration > 2s`
- æŸ¥æ‰¾é”™è¯¯: `error=true`
- æŒ‰æ“ä½œè¿‡æ»¤: `operation=llm.chat_completion`

---

## ğŸ“Š ç›‘æ§ API ç«¯ç‚¹

### LLM Metrics API

```bash
# è·å– LLM è°ƒç”¨æ±‡æ€»
curl http://localhost:8888/api/monitoring/llm/summary

# è·å–æœ€è¿‘çš„ LLM è°ƒç”¨
curl "http://localhost:8888/api/monitoring/llm/recent-calls?limit=10"

# æŒ‰æ¨¡å‹è¿‡æ»¤
curl "http://localhost:8888/api/monitoring/llm/summary?model=gpt-4o-mini"
```

### æ•°æ®è´¨é‡ API

```bash
# è·å–æ•°æ®è´¨é‡æ‘˜è¦
curl "http://localhost:8888/api/monitoring/data-quality/summary?interaction_type=chat"

# ç”Ÿæˆæ•°æ®æ¼‚ç§»æŠ¥å‘Š
curl -X POST http://localhost:8888/api/monitoring/data-quality/drift-report \
  -H "Content-Type: application/json" \
  -d '{
    "interaction_type": "chat",
    "reference_window": 1000,
    "current_window": 100
  }'
```

### RAG è¯„ä¼° API

```bash
# è¯„ä¼° RAG ç­”æ¡ˆè´¨é‡
curl -X POST http://localhost:8888/api/monitoring/rag/evaluate \
  -H "Content-Type: application/json" \
  -d '{
    "question": "What is machine learning?",
    "answer": "Machine learning is a subset of AI...",
    "contexts": ["Context from document 1", "Context from document 2"],
    "ground_truth": "Optional ground truth answer"
  }'

# è·å–è¯„ä¼°æ‘˜è¦
curl http://localhost:8888/api/monitoring/rag/evaluation-summary

# è·å–æœ€è¿‘çš„è¯„ä¼°
curl "http://localhost:8888/api/monitoring/rag/recent-evaluations?limit=10"
```

### å¥åº·æ£€æŸ¥

```bash
# ç›‘æ§ç³»ç»Ÿå¥åº·
curl http://localhost:8888/api/monitoring/health

# ç›‘æ§é…ç½®ä¿¡æ¯
curl http://localhost:8888/api/monitoring/config
```

---

## ğŸ§ª æµ‹è¯•ç›‘æ§åŠŸèƒ½

### 1. æµ‹è¯• LLM Metrics

```bash
# å‘é€èŠå¤©è¯·æ±‚
curl -X POST http://localhost:8888/api/chat/message \
  -H "Content-Type: application/json" \
  -d '{
    "message": "Hello, how are you?",
    "stream": false
  }'

# æŸ¥çœ‹æŒ‡æ ‡
curl http://localhost:8888/api/monitoring/llm/summary
```

### 2. æµ‹è¯• RAG è¯„ä¼°

```bash
# å‘é€ RAG æŸ¥è¯¢
curl -X POST http://localhost:8888/api/rag/ask \
  -H "Content-Type: application/json" \
  -d '{
    "question": "What is the capital of France?",
    "top_k": 5
  }'

# æŸ¥çœ‹ RAG è´¨é‡æ‘˜è¦
curl http://localhost:8888/api/monitoring/rag/evaluation-summary
```

### 3. æµ‹è¯•æ•°æ®æ¼‚ç§»æ£€æµ‹

```bash
# å‘é€å¤šä¸ªè¯·æ±‚ä»¥ç´¯ç§¯æ•°æ®
for i in {1..50}; do
  curl -X POST http://localhost:8888/api/chat/message \
    -H "Content-Type: application/json" \
    -d "{\"message\": \"Test message $i\", \"stream\": false}"
  sleep 0.5
done

# ç”Ÿæˆæ¼‚ç§»æŠ¥å‘Š
curl -X POST http://localhost:8888/api/monitoring/data-quality/drift-report \
  -H "Content-Type: application/json" \
  -d '{
    "interaction_type": "chat",
    "reference_window": 30,
    "current_window": 20
  }'
```

---

## ğŸ“ Prometheus æŸ¥è¯¢ç¤ºä¾‹

åœ¨ Prometheus UI (http://localhost:9090) æˆ– Grafana ä¸­ä½¿ç”¨:

```promql
# LLM Token ä½¿ç”¨é€Ÿç‡
rate(llm_token_usage_counter_total[5m])

# LLM æ¯ç§’æˆæœ¬
rate(llm_cost_counter_total[5m])

# P95 LLM å»¶è¿Ÿ
histogram_quantile(0.95, rate(llm_request_duration_histogram_bucket[5m]))

# RAG æ“ä½œé€Ÿç‡
rate(rag_operation_counter_total[5m])

# åµŒå…¥ç¼“å­˜å‘½ä¸­ç‡
sum(rate(embedding_counter_total{status="cache_hit"}[5m])) /
sum(rate(embedding_counter_total[5m]))

# LLM æˆåŠŸç‡
sum(rate(llm_request_counter_total{status="success"}[5m])) /
sum(rate(llm_request_counter_total[5m]))
```

---

## ğŸ”§ æ•…éšœæ’æŸ¥

### Grafana æ— æ³•è¿æ¥ Prometheus

```bash
# æ£€æŸ¥ Prometheus æ˜¯å¦è¿è¡Œ
docker logs prometheus

# éªŒè¯ Prometheus å¯è®¿é—®
curl http://localhost:9090/-/healthy
```

### Jaeger æ²¡æœ‰è¿½è¸ªæ•°æ®

```bash
# æ£€æŸ¥ backend ç¯å¢ƒå˜é‡
docker exec backend-api env | grep OTLP

# åº”è¯¥æ˜¾ç¤º:
# OTLP_ENDPOINT=http://jaeger:4317
# ENABLE_TELEMETRY=true

# æ£€æŸ¥ Jaeger æ—¥å¿—
docker logs jaeger
```

### ragas è¯„ä¼°å¤±è´¥

```bash
# æ£€æŸ¥ä¾èµ–æ˜¯å¦å®‰è£…
docker exec backend-api pip list | grep ragas

# æŸ¥çœ‹ backend æ—¥å¿—
docker logs backend-api | grep ragas
```

### Evidently æŠ¥å‘Šç”Ÿæˆå¤±è´¥

```bash
# æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿæ•°æ®
curl http://localhost:8888/api/monitoring/data-quality/summary?interaction_type=chat

# total_interactions åº”è¯¥ > reference_window + current_window
```

---

## ğŸ“Š æŒ‡æ ‡è¯´æ˜

### LLM Metrics

| æŒ‡æ ‡åç§° | ç±»å‹ | æè¿° |
|---------|------|------|
| `llm_token_usage_counter_total` | Counter | Token æ€»ä½¿ç”¨é‡ |
| `llm_cost_counter_total` | Counter | API è°ƒç”¨æ€»æˆæœ¬ (USD) |
| `llm_request_counter_total` | Counter | LLM è¯·æ±‚æ€»æ•° |
| `llm_request_duration_histogram` | Histogram | LLM è¯·æ±‚å»¶è¿Ÿåˆ†å¸ƒ |

### RAG Metrics

| æŒ‡æ ‡åç§° | ç±»å‹ | æè¿° |
|---------|------|------|
| `rag_operation_counter_total` | Counter | RAG æ“ä½œè®¡æ•° |
| `embedding_duration_histogram` | Histogram | åµŒå…¥ç”Ÿæˆå»¶è¿Ÿ |
| `rerank_duration_histogram` | Histogram | é‡æ’åºå»¶è¿Ÿ |
| `pgvector_query_duration_histogram` | Histogram | å‘é‡æœç´¢å»¶è¿Ÿ |
| `embedding_counter_total` | Counter | åµŒå…¥è¯·æ±‚è®¡æ•° |
| `rerank_counter_total` | Counter | é‡æ’åºè¯·æ±‚è®¡æ•° |

### RAG Quality Metrics (ragas)

| æŒ‡æ ‡åç§° | ç±»å‹ | æè¿° |
|---------|------|------|
| `rag_faithfulness_score` | Gauge | ç­”æ¡ˆå¿ å®åº¦ (0-1) |
| `rag_answer_relevancy_score` | Gauge | ç­”æ¡ˆç›¸å…³æ€§ (0-1) |
| `rag_context_precision_score` | Gauge | ä¸Šä¸‹æ–‡ç²¾ç¡®åº¦ (0-1) |
| `rag_context_recall_score` | Gauge | ä¸Šä¸‹æ–‡å¬å›ç‡ (0-1) |
| `rag_evaluation_duration_seconds` | Histogram | è¯„ä¼°è€—æ—¶ |

---

## ğŸ¯ æœ€ä½³å®è·µ

### 1. æŒç»­ç›‘æ§

- **æ¯æ—¥æ£€æŸ¥ Grafana ä»ªè¡¨æ¿**: è¯†åˆ«å¼‚å¸¸æ¨¡å¼
- **è®¾ç½®å‘Šè­¦**: åœ¨ Prometheus ä¸­é…ç½®å‘Šè­¦è§„åˆ™
- **å®šæœŸå®¡æŸ¥æˆæœ¬**: ç›‘æ§ LLM API æˆæœ¬è¶‹åŠ¿

### 2. æ€§èƒ½ä¼˜åŒ–

- **æŸ¥çœ‹ P95 å»¶è¿Ÿ**: è¯†åˆ«æ…¢è¯·æ±‚
- **ç›‘æ§ç¼“å­˜å‘½ä¸­ç‡**: ä¼˜åŒ–åµŒå…¥ç¼“å­˜ç­–ç•¥
- **è¿½è¸ªåˆ†å¸ƒå¼è°ƒç”¨**: ä½¿ç”¨ Jaeger å®šä½ç“¶é¢ˆ

### 3. è´¨é‡ä¿è¯

- **å®šæœŸè¿è¡Œ ragas è¯„ä¼°**: ç¡®ä¿ RAG ç­”æ¡ˆè´¨é‡
- **ç›‘æ§æ•°æ®æ¼‚ç§»**: æ£€æµ‹è¾“å…¥åˆ†å¸ƒå˜åŒ–
- **å®¡æŸ¥å¤±è´¥è¯·æ±‚**: åˆ†æé”™è¯¯æ¨¡å¼

### 4. æˆæœ¬ç®¡ç†

- **æŒ‰æ¨¡å‹è¿½è¸ªæˆæœ¬**: æ¯”è¾ƒä¸åŒæ¨¡å‹çš„æˆæœ¬æ•ˆç›Š
- **ç›‘æ§ token ä½¿ç”¨**: ä¼˜åŒ–æç¤ºè¯ä»¥å‡å°‘ token
- **è®¾ç½®æˆæœ¬è­¦æŠ¥**: é¿å…æ„å¤–è¶…æ”¯

---

## ğŸ“š ç›¸å…³æ–‡æ¡£

- **Prometheus**: https://prometheus.io/docs/
- **Grafana**: https://grafana.com/docs/
- **Jaeger**: https://www.jaegertracing.io/docs/
- **OpenTelemetry**: https://opentelemetry.io/docs/
- **Evidently**: https://docs.evidentlyai.com/
- **ragas**: https://docs.ragas.io/

---

## ğŸ†˜ è·å–å¸®åŠ©

- **é—®é¢˜åé¦ˆ**: https://github.com/anthropics/claude-code/issues
- **API æ–‡æ¡£**: http://localhost:8888/docs
- **ç›‘æ§é…ç½®**: http://localhost:8888/api/monitoring/config

---

**ç›‘æ§ç³»ç»Ÿç”± AI-Louie å›¢é˜Ÿç»´æŠ¤**
æœ€åæ›´æ–°: 2025-01-23
